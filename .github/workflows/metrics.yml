name: Collect Metrics & Deploy Dashboard

on:
  schedule:
    # Run daily at 2 AM UTC
    - cron: '0 2 * * *'

  workflow_dispatch:
    # Allow manual trigger via Actions tab

  push:
    branches:
      - main
    paths:
      - 'scripts/**'
      - 'tools/**'
      - 'config/**'
      - '.github/workflows/metrics.yml'

permissions:
  contents: read
  pages: write
  id-token: write

concurrency:
  group: "pages"
  cancel-in-progress: false

jobs:
  collect-metrics:
    name: Collect & Process Metrics
    runs-on: ubuntu-latest

    outputs:
      metrics-updated: ${{ steps.check-update.outputs.updated }}

    steps:
      - name: Checkout repository
        uses: actions/checkout@v3
        with:
          fetch-depth: 0

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.9'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install pyyaml

      - name: Run metrics collection pipeline
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          chmod +x run_metrics.sh
          chmod +x scripts/collect_metrics.py
          chmod +x scripts/compute_derived.py
          chmod +x tools/quality_gate.py

          echo "üîç Running evidence-backed metrics collection..."
          ./run_metrics.sh --range last_30_days

      - name: Build dashboard
        run: |
          chmod +x build_dashboard.sh
          echo "üìä Building dashboard from metrics..."
          ./build_dashboard.sh --artifacts artifacts --output public

      - name: Verify collection output
        id: check-update
        run: |
          if [ -f "artifacts/manifest.json" ]; then
            echo "updated=true" >> $GITHUB_OUTPUT
            echo "‚úÖ Metrics collection completed successfully"
            echo ""
            echo "üìä Metrics collected:"
            python3 -c "import json; m = json.load(open('artifacts/manifest.json')); print(f'  Time range: {m.get(\"time_range\")}'); print(f'  Metrics: {len(m.get(\"metrics_collected\", []))} collected'); print(f'  Quality gates: {m.get(\"quality_gates\", {}).get(\"evidence_completeness\")}')"
          else
            echo "‚ùå Metrics collection failed"
            exit 1
          fi

      - name: Upload artifacts
        uses: actions/upload-artifact@v4
        with:
          name: metrics-artifacts
          path: artifacts/
          retention-days: 30

  deploy-dashboard:
    name: Deploy Dashboard to GitHub Pages
    needs: collect-metrics
    runs-on: ubuntu-latest

    environment:
      name: github-pages
      url: ${{ steps.deployment.outputs.page_url }}

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Download metrics artifacts
        uses: actions/download-artifact@v4
        with:
          name: metrics-artifacts
          path: artifacts/

      - name: Prepare web content
        run: |
          echo "üìÅ Preparing web content..."
          mkdir -p public

          # Copy dashboard HTML
          if [ -f "public/index.html" ]; then
            echo "‚úÖ Dashboard exists at public/index.html"
          else
            echo "‚ö†Ô∏è Creating minimal dashboard"
            mkdir -p public
          fi

          # Copy metrics data and evidence
          mkdir -p public/data
          cp artifacts/manifest.json public/data/ 2>/dev/null || true
          cp artifacts/raw/*.json public/data/ 2>/dev/null || true
          cp artifacts/derived/*.json public/data/ 2>/dev/null || true

          # Copy documentation
          mkdir -p public/docs
          cp Documents/METHODOLOGY.md public/docs/ 2>/dev/null || true
          cp README_METRICS_SYSTEM.md public/ 2>/dev/null || true

          echo "‚úÖ Web content prepared"

      - name: Setup Pages
        uses: actions/configure-pages@v4

      - name: Upload artifact to Pages
        uses: actions/upload-pages-artifact@v3
        with:
          path: 'public'

      - name: Deploy to GitHub Pages
        id: deployment
        uses: actions/deploy-pages@v4

  notify-completion:
    name: Notify Completion
    needs: [collect-metrics, deploy-dashboard]
    runs-on: ubuntu-latest
    if: always()

    steps:
      - name: Check job status
        run: |
          COLLECT_STATUS="${{ needs.collect-metrics.result }}"
          DEPLOY_STATUS="${{ needs.deploy-dashboard.result }}"

          echo "========================================="
          echo "  Metrics Pipeline Complete"
          echo "========================================="
          echo ""
          echo "Metrics Collection: $COLLECT_STATUS"
          echo "Dashboard Deployment: $DEPLOY_STATUS"
          echo ""

          if [ "$COLLECT_STATUS" = "success" ] && [ "$DEPLOY_STATUS" = "success" ]; then
            echo "‚úÖ Evidence-Backed Metrics Pipeline PASSED"
            echo ""
            echo "üìä Dashboard available at:"
            echo "   https://vionascu.github.io/RnDMetrics/"
            echo ""
            echo "üìÅ Metrics Data:"
            echo "   - Evidence Trail: Check artifacts/manifest.json"
            echo "   - Raw Metrics: artifacts/raw/"
            echo "   - Derived Metrics: artifacts/derived/"
            echo ""
          else
            echo "‚ùå Pipeline FAILED"
            [ "$COLLECT_STATUS" != "success" ] && echo "  - Metrics collection failed"
            [ "$DEPLOY_STATUS" != "success" ] && echo "  - Dashboard deployment failed"
            exit 1
          fi
